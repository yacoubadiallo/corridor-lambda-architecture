FROM apache/spark:3.5.0

USER root

# Installation des outils Python
RUN apt-get update && apt-get install -y python3-pip && \
    pip3 install --upgrade pip && \
    pip3 install numpy pandas scipy scikit-learn pymongo kafka-python

# Variables d'environnement
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

# CORRECTION ICI : Passage Ã  la version 10.3.0 pour MongoDB
ENV PYSPARK_SUBMIT_ARGS="--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0 pyspark-shell"

WORKDIR /opt/spark